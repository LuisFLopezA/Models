{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://dinhanhthi.com/img/post/ML/random-forest-decision-tree/r2.jpg\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2023\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://dinhanhthi.com/img/post/ML/random-forest-decision-tree/r2.jpg</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Modelos basados en Árboles</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un árbol de decisión es un conjunto de sentencias de la forma: si... entonces...\n",
    "\n",
    "Estas sentencias dividen los datos en una serie de predictores. \n",
    "\n",
    "Estas divisiones de predictores son usadas para estimar la salida del modelo. \n",
    "\n",
    "**Ejemplo:** En un problema con dos predictores 'A' y 'B', un conjunto de sentencias de la forma:\n",
    "\n",
    "Si el predictor 'A' >= 1.7, entonces\n",
    "- Si el predictor B >=200, entonces la predicción = 1.3\n",
    "- De otra forma, la predicción = 2.5\n",
    "\n",
    "Estas sentencias están partiendo los predictores en 3 segmentos donde salidas específicas son definidas. \n",
    "\n",
    "**Estructura del árbol**\n",
    "\n",
    "Toma 3 cosas en cuenta:\n",
    "- Las variables predictoras (X) que se van a usar y el punto de partición del dataset.\n",
    "- La profundidad/complejidad del árbol\n",
    "- La ecuación de predicción en los últimos nodos/hojas del árbol\n",
    "\n",
    "**Hiperparámetros a ajustar**\n",
    "- Profundidad del árbol (max_depth)\n",
    "- Número mínimo de observaciones en cada split(min_samples_split)\n",
    "\n",
    "**Desventajas**\n",
    "\n",
    "- Inestabilidad del modelo: Debido a que las particiones se basan en un conjunto de datos, si se generan cambios en el conjunto de datos, esto genera cambios importantes en la estructura del árbol y especialmente en su interpretabilidad.\n",
    "\n",
    "- Rendimiento predictivo subóptimo. Nuevamente, debido a que las particiones se basan en un conjunto de datos específico, el modelo generalmente no converge con el modelo óptimo global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.tree import DecisionTreeRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear datos\n",
    "ColumnNames=['Hours','Calories', 'Weight']\n",
    "DataValues= [[1.0,   2500,   95],[2.0,   2000,   85],[2.5,   1900,   83],[3.0,   1850,   81],[3.5,   1600,   80],[4.0,   1500,   78],\n",
    "            [5.0,   1500,   77],[5.5,   1600,   80],[6.0,   1700,   75],[6.5,   1500,   70]]\n",
    "\n",
    "GymData=pd.DataFrame(data=DataValues,columns=ColumnNames)\n",
    "GymData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Target Variable and Predictor Variables\n",
    "TargetVariable='Weight'\n",
    "Predictors=['Hours','Calories']\n",
    "X=GymData[Predictors].values\n",
    "y=GymData[TargetVariable].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividir en entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializar el modelo\n",
    "model = DecisionTreeRegressor(random_state = 0)\n",
    "# entrenar el modelo \n",
    "model.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediciendo en los datos de prueba\n",
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular el error cuadrático medio\n",
    "mse = float(format(mean_squared_error(y_test, y_pred), '.3f'))\n",
    "print(\"\\nMSE: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular la r2\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"\\nMSE: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar el árbol\n",
    "from sklearn import tree\n",
    "tree.plot_tree(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correr en jupyter notebook:\n",
    "#pip install graphviz\n",
    "\n",
    "#correr en la consola de anaconda\n",
    "#conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportar el árbol\n",
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(model, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"trees_gen/tree_multipredict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observamos, el árbol está sobreajustando ya que tiene sólo un dato en cada hoja final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ventajas de los árboles de decisión**\n",
    "\n",
    "- No requiere escalamiento de variables\n",
    "- Puede  ser usado para datos no lineales\n",
    "- Fácil de visualizar\n",
    "- Fácil de interpretar\n",
    "\n",
    "**Desventajas de los árboles de decisión**\n",
    "\n",
    "- Es computancionalmente complejo, especialmente al usar cross-validation para ajustar los hiperparámetros\n",
    "- Un cambio pequeño en los datos puede causar grandes cambios en la estructura del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
